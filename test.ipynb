{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f438e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['author', 'content', 'datetime', 'source', 'summary', 'title', 'url',\n",
      "       'date', 'equity', 'extracted_summary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "path = r\"D:\\DeepFinance\\data\\interim\\news\\concatenated_news_filtered.parquet\"\n",
    "df = pd.read_parquet(path)\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c98660a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    }
   ],
   "source": [
    "path = r\"D:\\DeepFinance\\data\\processed\\unified_dataset_test.pkl\"\n",
    "import pickle as pkl \n",
    "with open(path, 'rb') as f: \n",
    "    data = pkl.load(f)\n",
    "\n",
    "date_with_news = 0 \n",
    "for d in data: \n",
    "    if data[d]['news']:\n",
    "        date_with_news += 1\n",
    "print(date_with_news)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c82543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading d:\\DeepFinance\\data\\processed\\unified_dataset_test.pkl...\n",
      "\n",
      "========================================\n",
      "üìä DATASET STATISTICS\n",
      "========================================\n",
      "Total Trading Days: 288\n",
      "Start Date: 2024-05-01\n",
      "End Date:   2025-06-25\n",
      "\n",
      "Days with Price/Macro:   288 (100%)\n",
      "Days with News:          288 (100.0%)\n",
      "Days with News Embed:    288 (100.0%)\n",
      "Days with Filings (10Q): 0 (0.0%)\n",
      "\n",
      "========================================\n",
      "üîç INSPECTING SAMPLE DATE: 2024-11-25\n",
      "========================================\n",
      "\n",
      "[1] Market Price:\n",
      "   - TSLA: {'open': Ticker\n",
      "TSLA    360.140015\n",
      "Name: 144, dtype: float64, 'high': Ticker\n",
      "TSLA    361.929993\n",
      "Name: 144, dtype: float64, 'close': Ticker\n",
      "TSLA    338.589996\n",
      "Name: 144, dtype: float64}\n",
      "   - AMZN: {'open': Ticker\n",
      "AMZN    199.279999\n",
      "Name: 144, dtype: float64, 'high': Ticker\n",
      "AMZN    201.949997\n",
      "Name: 144, dtype: float64, 'close': Ticker\n",
      "AMZN    201.449997\n",
      "Name: 144, dtype: float64}\n",
      "   - MSFT: {'open': Ticker\n",
      "MSFT    415.316296\n",
      "Name: 144, dtype: float64, 'high': Ticker\n",
      "MSFT    417.996506\n",
      "Name: 144, dtype: float64, 'close': Ticker\n",
      "MSFT    415.723297\n",
      "Name: 144, dtype: float64}\n",
      "\n",
      "[2] Macro Indicators:\n",
      "   - Keys: ['vix', 'yield_spread_10y_2y', 'sp500', 'sp500_return', 'dxy', 'wti']\n",
      "   - Sample (us10y): N/A\n",
      "\n",
      "[3] News Data:\n",
      "   - Tickers with news: ['AMZN', 'TSLA', 'MSFT', 'NFLX']\n",
      "   - Example (AMZN):\n",
      "     Title: Broncos-Chargers in, Browns-Bengals out in 'TNF' f...\n",
      "     Keys available: ['title', 'content', 'summary', 'source', 'url']\n",
      "\n",
      "[4] News Embeddings:\n",
      "   - Tickers with embeddings: ['AMZN', 'MSFT', 'NFLX', 'TSLA']\n",
      "   - Vector Type: <class 'list'>\n",
      "   - Vector Dimension: 1024\n",
      "   - Sample values: [-0.0039014897774904966, 0.05992187559604645, -0.034396927803754807, -0.037663865834474564, -0.006790557410567999]...\n",
      "\n",
      "========================================\n",
      "‚úÖ INSPECTION COMPLETE\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from configs.config import GlobalConfig\n",
    "\n",
    "def inspect_unified_dataset(filename='unified_dataset_test.pkl'):\n",
    "    file_path = os.path.join(GlobalConfig.PROCESSED_PATH, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ùå File not found: {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìÇ Loading {file_path}...\")\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # 1. Basic Stats\n",
    "    dates = sorted(list(data.keys()))\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"üìä DATASET STATISTICS\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total Trading Days: {len(dates)}\")\n",
    "    if dates:\n",
    "        print(f\"Start Date: {dates[0]}\")\n",
    "        print(f\"End Date:   {dates[-1]}\")\n",
    "    \n",
    "    # 2. Coverage Check\n",
    "    days_with_news = sum(1 for d in data if data[d].get('news'))\n",
    "    days_with_embed = sum(1 for d in data if data[d].get('news_embedding'))\n",
    "    days_with_filing_q = sum(1 for d in data if data[d].get('filing_q'))\n",
    "    \n",
    "    print(f\"\\nDays with Price/Macro:   {len(dates)} (100%)\")\n",
    "    print(f\"Days with News:          {days_with_news} ({days_with_news/len(dates)*100:.1f}%)\")\n",
    "    print(f\"Days with News Embed:    {days_with_embed} ({days_with_embed/len(dates)*100:.1f}%)\")\n",
    "    print(f\"Days with Filings (10Q): {days_with_filing_q} ({days_with_filing_q/len(dates)*100:.1f}%)\")\n",
    "\n",
    "    # 3. Detailed Inspection of a Sample Day\n",
    "    # Ch·ªçn ng√†y ·ªü gi·ªØa ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng d√≠nh ng√†y ƒë·∫ßu/cu·ªëi thi·∫øu d·ªØ li·ªáu\n",
    "    sample_date = dates[len(dates)//2] \n",
    "    sample_data = data[sample_date]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"üîç INSPECTING SAMPLE DATE: {sample_date}\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # --- Price ---\n",
    "    print(\"\\n[1] Market Price:\")\n",
    "    if sample_data.get('price'):\n",
    "        for ticker, val in list(sample_data['price'].items())[:3]: # Show max 3 tickers\n",
    "            print(f\"   - {ticker}: {val}\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Missing Price Data\")\n",
    "\n",
    "    # --- Macro ---\n",
    "    print(\"\\n[2] Macro Indicators:\")\n",
    "    if sample_data.get('macro'):\n",
    "        print(f\"   - Keys: {list(sample_data['macro'].keys())}\")\n",
    "        print(f\"   - Sample (us10y): {sample_data['macro'].get('us10y', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Missing Macro Data\")\n",
    "\n",
    "    # --- News ---\n",
    "    print(\"\\n[3] News Data:\")\n",
    "    news_data = sample_data.get('news', {})\n",
    "    if news_data:\n",
    "        tickers_with_news = list(news_data.keys())\n",
    "        print(f\"   - Tickers with news: {tickers_with_news}\")\n",
    "        \n",
    "        # Check structure of first news item\n",
    "        first_ticker = tickers_with_news[0]\n",
    "        first_news_item = news_data[first_ticker][0]\n",
    "        print(f\"   - Example ({first_ticker}):\")\n",
    "        print(f\"     Title: {first_news_item.get('title', 'N/A')[:50]}...\")\n",
    "        print(f\"     Keys available: {list(first_news_item.keys())}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è No news for this date\")\n",
    "\n",
    "    # --- Embedding ---\n",
    "    print(\"\\n[4] News Embeddings:\")\n",
    "    embed_data = sample_data.get('news_embedding', {})\n",
    "    if embed_data:\n",
    "        tickers_with_emb = list(embed_data.keys())\n",
    "        print(f\"   - Tickers with embeddings: {tickers_with_emb}\")\n",
    "        # Check vector shape\n",
    "        first_vec = embed_data[tickers_with_emb[0]]\n",
    "        print(f\"   - Vector Type: {type(first_vec)}\")\n",
    "        if isinstance(first_vec, (list, np.ndarray)):\n",
    "            print(f\"   - Vector Dimension: {len(first_vec)}\")\n",
    "            print(f\"   - Sample values: {first_vec[:5]}...\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è No embeddings for this date\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"‚úÖ INSPECTION COMPLETE\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_unified_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
